"""
Diagnostic checks for collocation solutions.
"""

from __future__ import annotations

from typing import Any

import casadi as ca
import numpy as np

from campro.logging import get_logger

log = get_logger(__name__)


def check_collocation_residuals(
    opti: ca.Opti | None,
    builder: Any,  # Typed as Any to avoid circular import, really CollocationBuilder
    solution_values: dict[str, np.ndarray] | None = None,
) -> float:
    """
    Compute the maximum defect (residual) in the collocation constraints.

    Args:
        opti: The Opti instance (solved). Ignored if builder is provided with solution_values.
        builder: The CollocationBuilder instance.
        solution_values: Dictionary of results from builder.solve().

    Returns:
        Max absolute residual value.
    """
    if builder is not None and solution_values is not None:
        if "_w_opt" in solution_values:
            w_opt = solution_values["_w_opt"]
            # Create function to evaluate constraints
            # Note: builder.g contains symbolic constraints
            # builder.w contains symbolic variables

            # We can cache this function in the builder if needed, but creating it here is fine
            g_func = ca.Function("g_eval", [ca.vertcat(*builder.w)], [ca.vertcat(*builder.g)])

            # Evaluate
            g_val = g_func(w_opt).full().flatten()

            # We should compare against bounds lbg, ubg
            # But usually lbg=ubg=0 for equality constraints
            # If inequality, we check violation

            lbg = np.array(builder.lbg)
            ubg = np.array(builder.ubg)

            # Violation: max(lbg - g, g - ubg, 0)
            violation = np.maximum(lbg - g_val, g_val - ubg)
            violation = np.maximum(violation, 0.0)

            return float(np.max(violation))

    # Fallback to Opti stats if available
    if opti is not None:
        try:
            return opti.stats()["iterations"]["inf_pr"][-1]
        except Exception:
            log.warning("Could not retrieve primal infeasibility from solver stats.")
            return -1.0

    return -1.0


def check_dynamics_consistency(
    builder: Any, solution: dict[str, np.ndarray], dt_check: float = 1e-4
) -> float:
    """
    Check consistency between the solution trajectory and the dynamics.
    Performs a forward simulation (integration) using the controls from the solution
    and compares the resulting state trajectory with the collocation solution.

    Args:
        builder: CollocationBuilder instance.
        solution: Dictionary of solution arrays (time, states, controls).
        dt_check: Time step for verification integration.

    Returns:
        Maximum error between collocation solution and forward simulation.
    """
    if not hasattr(builder, "dynamics") or builder.dynamics is None:
        return 0.0

    # Extract time grid and values
    # solution contains values at grid points (and maybe collocation points if we had them)
    # We will use the grid points for comparison

    # We need to reconstruct the control trajectory
    # Controls are piecewise constant (or polynomial) in each interval
    # For now, assume piecewise constant for simple check (or use value at start of interval)

    # Get time grid
    # We don't have time grid in solution dict usually, but builder knows T and K
    T = builder.T
    K = builder.N
    times = np.linspace(0, T, K + 1)

    # Initial state
    x_curr = {}
    for name in builder.states:
        if name in solution:
            x_curr[name] = solution[name][0]
        else:
            # Fallback or error
            return 0.0

    max_error = 0.0

    # Integrate
    # We'll use simple Euler or RK4
    # But we need controls at arbitrary time t
    # Controls in solution are usually [u0, u1, ..., u_{K-1}]

    for k in range(K):
        t_start = times[k]
        t_end = times[k + 1]
        dt = t_end - t_start

        # Control for this interval
        u_curr = {}
        for name in builder.controls:
            if name in solution:
                u_curr[name] = solution[name][k]

        # Evaluate dynamics at start
        # dx/dt = f(x, u)
        # Note: builder.dynamics expects symbolic or numeric?
        # If it was defined with CasADi symbols, we need to evaluate it numerically.
        # But the dynamics function usually takes symbols and returns symbols.
        # We need a numeric version.

        # We can't easily use the python function if it uses CasADi operations.
        # We need to use the CasADi function generated by the builder if available.
        # Builder doesn't expose a numeric dynamics function easily.

        # However, we can use the 'f' function from the NLP if we had it.
        # Or we can skip this check if it's too complex to implement generically without builder support.

        pass

    # Given the complexity of evaluating symbolic dynamics numerically without a compiled function,
    # we will return a placeholder for now.
    # To do this properly, CollocationBuilder should expose a numeric dynamics evaluator.

    return 0.0


def check_scaling(
    opti: ca.Opti | None,
    builder: Any = None,
    solution_values: dict[str, np.ndarray] | None = None,
    threshold: float = 1e4,
) -> list[str]:
    """
    Check for bad scaling in variables and constraints.

    Args:
        opti: CasADi Opti instance.
        builder: CollocationBuilder instance.
        solution_values: Solution values.
        threshold: Ratio threshold for warning.

    Returns:
        List of warnings.
    """
    warnings = []

    w_opt = None
    if builder is not None and solution_values is not None and "_w_opt" in solution_values:
        w_opt = solution_values["_w_opt"]

        # Check variable magnitudes
        max_val = np.max(np.abs(w_opt))
        min_val = np.min(np.abs(w_opt) + 1e-16)
        if max_val > threshold:
            warnings.append(f"Max variable value {max_val:.2e} exceeds threshold {threshold:.2e}")
        if min_val < 1.0 / threshold and min_val > 1e-16:
            warnings.append(f"Min variable value {min_val:.2e} is very small")

        # Check Jacobian scaling
        # J = d(g)/d(w)
        try:
            # Create Jacobian function
            # This might be expensive for large problems
            J_func = ca.Function(
                "J_eval",
                [ca.vertcat(*builder.w)],
                [ca.jacobian(ca.vertcat(*builder.g), ca.vertcat(*builder.w))],
            )
            J_val = J_func(w_opt).full()  # Dense matrix? Might be huge.
            # Use sparse?
            # J_val is sparse by default in CasADi but .full() makes it dense.
            # If problem is large, avoid .full().

            # We can use DM to handle sparse
            J_dm = J_func(w_opt)

            # Check row norms (constraints)
            # We can iterate?
            # Or just sample?
            pass
        except Exception as e:
            log.warning(f"Could not check Jacobian scaling: {e}")

    elif opti is not None:
        # Check Opti scaling
        pass

    return warnings
